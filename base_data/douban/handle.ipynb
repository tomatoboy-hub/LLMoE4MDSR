{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_category = [\"book\", \"movie\", \"music\"]\n",
    "# flag: book: 0, movie: 1, music: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. read_data: 把所有数据读出来，然后存到一个list中\n",
    "2. filter: 单纯过滤掉交互过小的交互，返回的还是list\n",
    "3. id_map: 制作user和item的dict映射，并拆掉list，变成一个用户的交互序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_category, domain_flag):\n",
    "    data_path = r\"./raw/douban/{}reviews_cleaned.txt\".format(data_category)\n",
    "    lines = open(data_path).readlines()\n",
    "    \n",
    "    data = []\n",
    "    for line in tqdm(lines[1:]):\n",
    "\n",
    "        if domain_flag == 0:\n",
    "            user_id, item_id, rating, label, comment, time, inter_id = line.strip().split(\"\\t\")\n",
    "        elif domain_flag == 1:\n",
    "            try:    # some uncleaned data\n",
    "                user_id, item_id, rating, comment, time, label, _, _, inter_id = line.strip().split(\"\\t\")\n",
    "            except:\n",
    "                continue\n",
    "        elif domain_flag == 2:\n",
    "            user_id, item_id, rating, label, comment, _, time, inter_id = line.strip().split(\"\\t\")\n",
    "        \n",
    "        user_id = int(user_id.replace('\"', ''))\n",
    "        item_id = int(item_id.replace('\"', ''))\n",
    "        label = label.replace('\"', '')\n",
    "                \n",
    "        data.append([user_id, \n",
    "                    item_id, \n",
    "                    # float(rating.replace('\"', '')), \n",
    "                    label,\n",
    "                    # str(comment.replace('\"', '')), \n",
    "                    int(time.replace('\"', '').replace('-','').replace(':','').replace(' ','')), \n",
    "                    # str(inter_id.replace('\"', '')),\n",
    "                    domain_flag])\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_inter(data):\n",
    "    \n",
    "    user_count = {}\n",
    "    item_count = {}\n",
    "    for inter in data:\n",
    "        user_id, item_id, _, _, _ = inter\n",
    "        \n",
    "        if user_id not in user_count.keys():\n",
    "            user_count[user_id] = 1\n",
    "        else:\n",
    "            user_count[user_id] += 1\n",
    "\n",
    "        if item_id not in item_count.keys():\n",
    "            item_count[item_id] = 1\n",
    "        else:\n",
    "            item_count[item_id] += 1\n",
    "    \n",
    "    return user_count, item_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(data, user_minmum, item_minimum, \n",
    "           t_min=20160101, t_max=20161232):   # 过滤掉交互少的数据\n",
    "    \n",
    "    user_count, item_count = count_inter(data)\n",
    "    domain_set = {0: {\"user\": [], \"item\": []},\n",
    "                  1: {\"user\": [], \"item\": []},\n",
    "                  2: {\"user\": [], \"item\": []},}\n",
    "    new_data = []\n",
    "\n",
    "    for inter in tqdm(data):\n",
    "        user_id, item_id, _, time, domain_id = inter\n",
    "        \n",
    "        if item_count[item_id] > item_minimum and user_count[user_id] > user_minmum \\\n",
    "            and time > t_min and time < t_max:\n",
    "            \n",
    "            new_data.append(inter)\n",
    "            domain_set[domain_id][\"user\"].append(user_id)\n",
    "            domain_set[domain_id][\"item\"].append(item_id)\n",
    "    \n",
    "    print(\"filter done!\")\n",
    "\n",
    "    return new_data, domain_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequence(data):\n",
    "\n",
    "    seq = {}\n",
    "    domain_seq = {}\n",
    "\n",
    "    for inter in tqdm(data):\n",
    "        user_id, item_id, label, time, domain_id = inter\n",
    "        if user_id not in seq.keys():\n",
    "            seq[user_id] = [item_id]\n",
    "            domain_seq[user_id] = [domain_id]\n",
    "        else:\n",
    "            seq[user_id].append(item_id)\n",
    "            domain_seq[user_id].append(domain_id)\n",
    "\n",
    "    return seq, domain_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_map(data, domain_set):\n",
    "    \n",
    "    final_data, final_domain = {}, {}\n",
    "    temp_data = {}\n",
    "    new_user_id = 1\n",
    "    temp_item_count = {domain_id: len(set(domain_set[domain_id][\"item\"])) for domain_id in domain_set.keys()}\n",
    "    item_count = {0: 1, 1: 1, 2: 1}\n",
    "    item_dict = {\n",
    "        0: {\"str2id\": {}, \"id2str\": {}, \"id2label\": {},},\n",
    "        1: {\"str2id\": {}, \"id2str\": {}, \"id2label\": {},},\n",
    "        2: {\"str2id\": {}, \"id2str\": {}, \"id2label\": {},},\n",
    "    }\n",
    "    user_dict = {\"str2id\": {}, \"id2str\": {},}\n",
    "\n",
    "    for inter in tqdm(data):\n",
    "        user_id, item_id, label, time, domain_id = inter\n",
    "            \n",
    "        if item_id not in item_dict[domain_id][\"str2id\"].keys():\n",
    "            new_item_id = item_count[domain_id]\n",
    "            item_dict[domain_id][\"str2id\"][item_id] = new_item_id\n",
    "            item_dict[domain_id][\"id2str\"][new_item_id] = item_id\n",
    "            item_dict[domain_id][\"id2label\"][new_item_id] = [label]\n",
    "            item_count[domain_id] += 1\n",
    "        else: # add label as the description of items\n",
    "            if label not in item_dict[domain_id][\"id2label\"][item_dict[domain_id][\"str2id\"][item_id]]:\n",
    "                item_dict[domain_id][\"id2label\"][item_dict[domain_id][\"str2id\"][item_id]].append(label)\n",
    "        \n",
    "        if user_id not in user_dict[\"str2id\"].keys():\n",
    "            user_dict[\"str2id\"][user_id] = new_user_id\n",
    "            user_dict[\"id2str\"][new_user_id] = user_id\n",
    "            temp_data[new_user_id] = [(item_dict[domain_id][\"str2id\"][item_id], domain_id, time)]\n",
    "            new_user_id += 1\n",
    "        else:\n",
    "            temp_data[user_dict[\"str2id\"][user_id]].append((item_dict[domain_id][\"str2id\"][item_id], domain_id, time))\n",
    "\n",
    "    print(\"map done!\")\n",
    "\n",
    "    for user_id, inter in tqdm(temp_data.items()):\n",
    "\n",
    "        inter.sort(key=lambda x: x[2])\n",
    "        final_data[user_id] = [temp_tuple[0] for temp_tuple in inter]\n",
    "        final_domain[user_id] = [temp_tuple[1] for temp_tuple in inter]\n",
    "\n",
    "    print(\"sort done!\")\n",
    "    \n",
    "    return final_data, final_domain, user_dict, item_dict, item_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "# all_item = []\n",
    "for flag, category in enumerate(data_category):\n",
    "    data = read_data(category, flag)\n",
    "    all_data.append(data)\n",
    "    # all_item.append(item_dict)\n",
    "    print(\"{} is done\".format(category))\n",
    "all_data = all_data[0] + all_data[1] + all_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计数据集的交互在时间上的分布\n",
    "# time_list = []\n",
    "# for inter in all_data[0]:\n",
    "#     _, _, _, inter_time, _ = inter\n",
    "#     time_list.append(inter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(time_list, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data, domain_set = filter(all_data, user_minmum=1, item_minimum=2)\n",
    "final_data, final_domain, user_dict, item_dict, item_count = id_map(new_data, domain_set)\n",
    "item_count = {domain_id: len(set(domain_set[domain_id][\"item\"])) for domain_id in domain_set.keys()}\n",
    "item_dict[\"item_count\"] = item_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq, domain_seq = make_sequence(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book和movie两个domain交集的用户数量\n",
    "len(set(domain_set[0][\"user\"]) & set(domain_set[1][\"user\"])), len(set(domain_set[0][\"user\"])), len(set(domain_set[1][\"user\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证map是否能对上\n",
    "print(item_count)\n",
    "max(item_dict[0][\"str2id\"].values()), max(item_dict[1][\"str2id\"].values()), max(item_dict[2][\"str2id\"].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把所有数据先存下来\n",
    "可以使用final_domain去进行数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./handled/id_map.json\", \"w\") as f:\n",
    "    json.dump({\"user_dict\": user_dict, \"item_dict\": item_dict}, f)\n",
    "with open(\"./handled/douban_all.pkl\", \"wb\") as f:\n",
    "    pickle.dump((final_data, final_domain), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./handled/id_map.json\", \"r\") as f:\n",
    "    map_dict = json.load(f)\n",
    "user_dict = map_dict[\"user_dict\"]\n",
    "item_dict = map_dict[\"item_dict\"]\n",
    "\n",
    "with open(\"./handled/douban_all.pkl\", \"rb\") as f:\n",
    "    final_data, final_domain = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "筛选book-movie两个domain\n",
    "\n",
    "这里选的是book和movie两个domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 先筛选final_data和final_domain\n",
    "bm_data, bm_domain = {}, {}\n",
    "for user_id, inter in tqdm(final_domain.items()):\n",
    "    inter = np.array(inter)\n",
    "    inter_data = np.array(final_data[user_id])\n",
    "    bm_data[user_id] = inter_data[np.where(np.logical_or(inter==0, inter == 1))]\n",
    "    bm_domain[user_id] = inter[np.where(np.logical_or(inter==0, inter == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_stats = []\n",
    "for inter in bm_domain.values():\n",
    "    domain_stats.append(np.mean(inter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计两个domain中overlap的用户\n",
    "domain_stats = np.array(domain_stats)\n",
    "domain_stats[domain_stats==0].shape[0], domain_stats[domain_stats==1].shape[0], domain_stats.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计整体序列的长度\n",
    "inter_len = []\n",
    "for inter in bm_data.values():\n",
    "    inter_len.append(len(inter))\n",
    "print(np.mean(inter_len))\n",
    "plt.hist(inter_len, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_len = np.array(inter_len)\n",
    "len(inter_len[inter_len>200]) / len(inter_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./handled/book_movie.pkl\", \"wb\") as f:\n",
    "    pickle.dump((bm_data, bm_domain), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计重复交互的问题\n",
    "# _, i_counts = np.unique(bm_data[0], return_counts=True)\n",
    "# np.sum(i_counts), len(i_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要构造cold-start场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_all_data = []\n",
    "for flag, category in enumerate([\"book\", \"movie\"]):\n",
    "    data = read_data(category, flag)\n",
    "    cold_all_data.append(data)\n",
    "    # all_item.append(item_dict)\n",
    "    print(\"{} is done\".format(category))\n",
    "cold_all_data = cold_all_data[0] + cold_all_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cold_filter(data, item_dict, t_min=20170101, t_max=20171232):   # 过滤掉交互少的数据\n",
    "    \n",
    "    domain_set = {0: {\"user\": [], \"item\": []},\n",
    "                  1: {\"user\": [], \"item\": []},\n",
    "                  2: {\"user\": [], \"item\": []},}\n",
    "    new_data = []\n",
    "\n",
    "    for inter in tqdm(data):\n",
    "        user_id, item_id, _, time, domain_id = inter\n",
    "        \n",
    "        if time > t_min and time < t_max \\\n",
    "            and item_id in item_dict[domain_id][\"str2id\"].keys():\n",
    "            \n",
    "            new_data.append(inter)\n",
    "            domain_set[domain_id][\"user\"].append(user_id)\n",
    "            domain_set[domain_id][\"item\"].append(item_id)\n",
    "    \n",
    "    print(\"filter done!\")\n",
    "\n",
    "    return new_data, domain_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cold_data, cold_domain_set = cold_filter(cold_all_data, item_dict)\n",
    "final_cold_data, final_cold_domain, _, _, _ = id_map(new_cold_data, cold_domain_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = {0: 0, 1: 0}\n",
    "filter_cold_data, filter_cold_domain = {}, {}\n",
    "\n",
    "for i in tqdm(range(1, len(final_cold_data))):\n",
    "    random_inter, random_domain = final_cold_data[i], final_cold_domain[i]\n",
    "    temp_seq, temp_domain = [], []\n",
    "    flag = False    # mark whether has cross domain\n",
    "    \n",
    "    if len(random_inter) < 3:\n",
    "        continue\n",
    "\n",
    "    for j in range(len(random_inter)-1):\n",
    "        temp_seq.append(random_inter[j])\n",
    "        temp_domain.append(random_domain[j])\n",
    "        if random_domain[j] != random_domain[j+1]:\n",
    "            flag = True\n",
    "            break\n",
    "    \n",
    "    if len(temp_seq) > 3 and flag and random_num[random_domain[j+1]]<60:\n",
    "        temp_seq.append(random_inter[j+1])\n",
    "        temp_domain.append(random_domain[j+1])\n",
    "        filter_cold_data[i] = np.array(temp_seq)\n",
    "        filter_cold_domain[i] = np.array(temp_domain)\n",
    "        random_num[random_domain[j+1]] += 1\n",
    "\n",
    "    if (random_num[0]+random_num[1]) > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_flag = []\n",
    "for meta_domain_seq in filter_cold_domain.values():\n",
    "    domain_flag.append(meta_domain_seq[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(domain_flag) # the number of movie domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./handled/book_movie_cold.pkl\", \"wb\") as f:\n",
    "    pickle.dump((filter_cold_data, filter_cold_domain), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_domain = {0: 0, 1: 0, 2: 0}\n",
    "inter_len = []\n",
    "new_inter_len = []\n",
    "for domain_inter in final_domain.values():\n",
    "    target_domain = domain_inter[-1]\n",
    "    test_domain[target_domain] += 1\n",
    "    inter_len.append(len(domain_inter))\n",
    "    new_inter = np.array(domain_inter)\n",
    "    new_inter = new_inter[np.where(np.logical_or(new_inter==0, new_inter == 2))]\n",
    "    new_inter_len.append(len(new_inter))\n",
    "test_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_len = np.array(inter_len)\n",
    "inter_len[inter_len>100]=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inter_len = np.array(new_inter_len)\n",
    "new_inter_len[new_inter_len>100]=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(new_inter_len, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{domain_id: len(set(domain_set[domain_id][\"user\"])) for domain_id in domain_set.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inter = {}\n",
    "start_id = 1\n",
    "user_dict = {\"str2id\": {}, \"id2str\": {}}\n",
    "for inter in tqdm(all_data):\n",
    "    user_id, item_id, time, domain = inter\n",
    "\n",
    "    if user_id not in user_dict[\"str2id\"].keys():\n",
    "        user_dict[\"str2id\"][user_id] = start_id\n",
    "        user_dict[\"id2str\"][start_id] = user_id\n",
    "        user_inter[start_id] = [(item_id, time, domain)]\n",
    "        start_id += 1\n",
    "    else:\n",
    "        user_inter[user_dict[\"str2id\"][user_id]].append((item_id, time, domain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id in tqdm(user_inter.keys()):\n",
    "    user_inter[user_id].sort(key=lambda x: x[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
