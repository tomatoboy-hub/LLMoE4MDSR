{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from data_process import New_Amazon, Amazon_meta\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把两个独立的Amazon数据读进来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_A = \"Clothing_Shoes_and_Jewelry\"\n",
    "domain_B = \"Sports_and_Outdoors\"\n",
    "data_A = New_Amazon(domain_A, 0)\n",
    "data_B = New_Amazon(domain_B, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给每个交互添加domain id\n",
    "new_data_A, new_data_B = [], []\n",
    "for inter in tqdm(data_A):\n",
    "    new_inter = list(inter)\n",
    "    new_inter.append(0)\n",
    "    new_data_A.append(new_inter)\n",
    "for inter in tqdm(data_B):\n",
    "    new_inter = list(inter)\n",
    "    new_inter.append(1)\n",
    "    new_data_B.append(new_inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. read_data: 把所有数据读出来，然后存到一个list中\n",
    "2. filter: 单纯过滤掉交互过小的交互，返回的还是list\n",
    "3. id_map: 制作user和item的dict映射，并拆掉list，变成一个用户的交互序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_inter(data, t_min, t_max):\n",
    "    \n",
    "    user_count = {}\n",
    "    item_count = {}\n",
    "    for inter in data:\n",
    "        user_id, item_id, time, _ = inter\n",
    "        \n",
    "        if user_id not in user_count.keys():\n",
    "            user_count[user_id] = 1\n",
    "        else:\n",
    "            if time > t_min and time < t_max:\n",
    "                user_count[user_id] += 1\n",
    "\n",
    "        if item_id not in item_count.keys():\n",
    "            item_count[item_id] = 1\n",
    "        else:\n",
    "            if time > t_min and time < t_max:\n",
    "                item_count[item_id] += 1\n",
    "\n",
    "    \n",
    "    return user_count, item_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(data, user_minmum, item_minimum, t_min=1451577600, t_max=1459440000):   # 过滤掉交互少的数据\n",
    "    \n",
    "    user_count, item_count = count_inter(data, t_min=t_min, t_max=t_max)\n",
    "    domain_set = {0: {\"user\": [], \"item\": []},\n",
    "                  1: {\"user\": [], \"item\": []},\n",
    "                  }\n",
    "    new_data = []\n",
    "\n",
    "    for inter in tqdm(data):\n",
    "        user_id, item_id, time, domain_id = inter\n",
    "        \n",
    "        if item_count[item_id] > item_minimum and user_count[user_id] > user_minmum \\\n",
    "           and time > t_min and time < t_max:    # 只取2016-01-01到2016-01-15之间的数据\n",
    "            \n",
    "            new_data.append(inter)\n",
    "            domain_set[domain_id][\"user\"].append(user_id)\n",
    "            domain_set[domain_id][\"item\"].append(item_id)\n",
    "    \n",
    "    print(\"filter done!\")\n",
    "\n",
    "    return new_data, domain_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequence(data):\n",
    "\n",
    "    seq = {}\n",
    "    domain_seq = {}\n",
    "\n",
    "    for inter in tqdm(data):\n",
    "        user_id, item_id, time, domain_id = inter\n",
    "        if user_id not in seq.keys():\n",
    "            seq[user_id] = [item_id]\n",
    "            domain_seq[user_id] = [domain_id]\n",
    "        else:\n",
    "            seq[user_id].append(item_id)\n",
    "            domain_seq[user_id].append(domain_id)\n",
    "\n",
    "    return seq, domain_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_map(data, domain_set):\n",
    "    \n",
    "    final_data, final_domain = {}, {}\n",
    "    temp_data = {}\n",
    "    new_user_id = 1\n",
    "    temp_item_count = {domain_id: len(set(domain_set[domain_id][\"item\"])) for domain_id in domain_set.keys()}\n",
    "    item_count = {0: 1, 1: 1}\n",
    "    item_dict = {\n",
    "        0: {\"str2id\": {}, \"id2str\": {},},\n",
    "        1: {\"str2id\": {}, \"id2str\": {},},\n",
    "    }\n",
    "    user_dict = {\"str2id\": {}, \"id2str\": {},}\n",
    "\n",
    "    for inter in tqdm(data):\n",
    "        user_id, item_id, time, domain_id = inter\n",
    "            \n",
    "        if item_id not in item_dict[domain_id][\"str2id\"].keys():\n",
    "            new_item_id = item_count[domain_id]\n",
    "            item_dict[domain_id][\"str2id\"][item_id] = new_item_id\n",
    "            item_dict[domain_id][\"id2str\"][new_item_id] = item_id\n",
    "            item_count[domain_id] += 1\n",
    "        \n",
    "        if user_id not in user_dict[\"str2id\"].keys():\n",
    "            user_dict[\"str2id\"][user_id] = new_user_id\n",
    "            user_dict[\"id2str\"][new_user_id] = user_id\n",
    "            temp_data[new_user_id] = [(item_dict[domain_id][\"str2id\"][item_id], domain_id, time)]\n",
    "            new_user_id += 1\n",
    "        else:\n",
    "            temp_data[user_dict[\"str2id\"][user_id]].append((item_dict[domain_id][\"str2id\"][item_id], domain_id, time))\n",
    "\n",
    "    print(\"map done!\")\n",
    "\n",
    "    for user_id, inter in tqdm(temp_data.items()):\n",
    "\n",
    "        inter.sort(key=lambda x: x[2])\n",
    "        final_data[user_id] = [temp_tuple[0] for temp_tuple in inter]\n",
    "        final_domain[user_id] = [temp_tuple[1] for temp_tuple in inter]\n",
    "\n",
    "    print(\"sort done!\")\n",
    "    \n",
    "    return final_data, final_domain, user_dict, item_dict, item_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-core user_core item_core\n",
    "def check_Kcore(data, user_core, item_core):\n",
    "\n",
    "    user_count = {}\n",
    "    item_count = {}\n",
    "    for inter in data:\n",
    "        user_id, item_id, time, _ = inter\n",
    "        \n",
    "        if user_id not in user_count.keys():\n",
    "            user_count[user_id] = 1\n",
    "        else:\n",
    "            user_count[user_id] += 1\n",
    "\n",
    "        if item_id not in item_count.keys():\n",
    "            item_count[item_id] = 1\n",
    "        else:\n",
    "            item_count[item_id] += 1\n",
    "\n",
    "    for _, num in user_count.items():\n",
    "        if num < user_core:\n",
    "            return user_count, item_count, False\n",
    "    for _, num in item_count.items():\n",
    "        if num < item_core:\n",
    "            return user_count, item_count, False\n",
    "        \n",
    "    return user_count, item_count, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 循环过滤 K-core\n",
    "def filter_Kcore(data, user_core, item_core): # user 接所有items\n",
    "    \n",
    "    user_count, item_count, isKcore = check_Kcore(data, user_core, item_core)\n",
    "    \n",
    "    new_data = data\n",
    "\n",
    "    while not isKcore:\n",
    "\n",
    "        temp_data = []\n",
    "        domain_set = {\n",
    "            0: {\"user\": [], \"item\": []},\n",
    "            1: {\"user\": [], \"item\": []},\n",
    "        }\n",
    "\n",
    "        for inter in tqdm(new_data):\n",
    "            user_id, item_id, time, domain_id = inter\n",
    "            \n",
    "            if item_count[item_id] > item_core and user_count[user_id] > user_core:    # 只取2016-01-01到2016-01-15之间的数据\n",
    "                \n",
    "                temp_data.append(inter)\n",
    "                domain_set[domain_id][\"user\"].append(user_id)\n",
    "                domain_set[domain_id][\"item\"].append(item_id)\n",
    "        user_count, item_count, isKcore = check_Kcore(temp_data, user_core, item_core)\n",
    "\n",
    "        new_data = temp_data\n",
    "\n",
    "    print(\"K-core filter done!\")\n",
    "\n",
    "    return new_data, domain_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_time(data, t_min=1451577600, t_max=1459440000):   # 过滤掉交互少的数据\n",
    "    \n",
    "\n",
    "    new_data = []\n",
    "\n",
    "    for inter in tqdm(data):\n",
    "        _, _, time, _ = inter\n",
    "        \n",
    "        if time > t_min and time < t_max:    # 只取2016-01-01到2016-01-15之间的数据\n",
    "            \n",
    "            new_data.append(inter)\n",
    "\n",
    "    print(\"filter time done!\")\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = []\n",
    "for inter in tqdm(new_data_A+new_data_B):\n",
    "    _, _, time, _ = inter\n",
    "    time_list.append(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(time_list, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = new_data_A + new_data_B\n",
    "# new_data, domain_set = filter(all_data, user_minmum=10, item_minimum=10)\n",
    "all_data = filter_time(all_data, t_min=1514736000, t_max=1577808000)\n",
    "new_data, domain_set = filter_Kcore(all_data, user_core=5, item_core=3)\n",
    "final_data, final_domain, user_dict, item_dict, item_count = id_map(new_data, domain_set)\n",
    "item_count = {domain_id: len(set(domain_set[domain_id][\"item\"])) for domain_id in domain_set.keys()}\n",
    "item_dict[\"item_count\"] = item_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book和movie两个domain交集的用户数量\n",
    "len(set(domain_set[0][\"user\"]) & set(domain_set[1][\"user\"])), len(set(domain_set[0][\"user\"])), len(set(domain_set[1][\"user\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain A中物品数量, domian B中物品数量, 用户数量\n",
    "len(item_dict[0][\"str2id\"]), len(item_dict[1][\"str2id\"]), len(user_dict[\"str2id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证map是否能对上\n",
    "print(item_count)\n",
    "max(item_dict[0][\"str2id\"].values()), max(item_dict[1][\"str2id\"].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把所有数据先存下来\n",
    "可以使用final_domain去进行数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./handled/id_map.json\", \"w\") as f:\n",
    "    json.dump({\"user_dict\": user_dict, \"item_dict\": item_dict}, f)\n",
    "with open(\"./handled/amazon_all.pkl\", \"wb\") as f:\n",
    "    pickle.dump((final_data, final_domain), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./handled/id_map.json\", \"r\") as f:\n",
    "    map_dict = json.load(f)\n",
    "user_dict = map_dict[\"user_dict\"]\n",
    "item_dict = map_dict[\"item_dict\"]\n",
    "\n",
    "with open(\"./handled/amazon_all.pkl\", \"rb\") as f:\n",
    "    final_data, final_domain = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "筛选book-movie两个domain\n",
    "\n",
    "这里选的是book和movie两个domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 先筛选final_data和final_domain\n",
    "bm_data, bm_domain = {}, {}\n",
    "for user_id, inter in tqdm(final_domain.items()):\n",
    "    inter = np.array(inter)\n",
    "    inter_data = np.array(final_data[user_id])\n",
    "    bm_data[user_id] = inter_data[np.where(np.logical_or(inter==0, inter == 1))]\n",
    "    bm_domain[user_id] = inter[np.where(np.logical_or(inter==0, inter == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_stats = []\n",
    "for inter in bm_domain.values():\n",
    "    domain_stats.append(np.mean(inter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计两个domain中overlap的用户\n",
    "domain_stats = np.array(domain_stats)\n",
    "domain_stats[domain_stats==0].shape[0], domain_stats[domain_stats==1].shape[0], domain_stats.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计整体序列的长度\n",
    "inter_len = []\n",
    "for inter in bm_data.values():\n",
    "    inter_len.append(len(inter))\n",
    "print(np.mean(inter_len))\n",
    "plt.hist(inter_len, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(inter_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计物品的交互次数\n",
    "item_freq = {\n",
    "        0: np.zeros(item_count[0]+1),\n",
    "        1: np.zeros(item_count[1]+1),\n",
    "    }\n",
    "for user_id in tqdm(final_data.keys()):\n",
    "    seq = final_data[user_id]\n",
    "    domain_seq = final_domain[user_id]\n",
    "    for i in range(len(seq)):\n",
    "        item_freq[domain_seq[i]][seq[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方便画频率分布直方图\n",
    "item_freq[0][item_freq[0]>30] = 30\n",
    "item_freq[1][item_freq[1]>30] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(item_freq[0]), np.mean(item_freq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(item_freq[0], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(item_freq[1], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_len = np.array(inter_len)\n",
    "len(inter_len[inter_len>200]) / len(inter_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./handled/cloth_sport.pkl\", \"wb\") as f:\n",
    "    pickle.dump((bm_data, bm_domain), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计重复交互的问题\n",
    "# _, i_counts = np.unique(bm_data[0], return_counts=True)\n",
    "# np.sum(i_counts), len(i_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attribute_Amazon(meta_infos, datamaps, attribute_core):\n",
    "\n",
    "    attributes = defaultdict(int)\n",
    "    # 做映射\n",
    "    attribute2id = {}\n",
    "    id2attribute = {}\n",
    "    attributeid2num = defaultdict(int)\n",
    "    attribute_id = 1\n",
    "    items2attributes = {}\n",
    "    attribute_lens = []\n",
    "\n",
    "    for iid, attributes in meta_infos.items():\n",
    "        item_id = datamaps['item2id'][iid]\n",
    "        items2attributes[item_id] = []\n",
    "        for attribute in attributes:\n",
    "            if attribute not in attribute2id:\n",
    "                attribute2id[attribute] = attribute_id\n",
    "                id2attribute[attribute_id] = attribute\n",
    "                attribute_id += 1\n",
    "            attributeid2num[attribute2id[attribute]] += 1\n",
    "            items2attributes[item_id].append(attribute2id[attribute])\n",
    "        attribute_lens.append(len(items2attributes[item_id]))\n",
    "    print(f'before delete, attribute num:{len(attribute2id)}')\n",
    "    print(f'attributes len, Min:{np.min(attribute_lens)}, Max:{np.max(attribute_lens)}, Avg.:{np.mean(attribute_lens):.4f}')\n",
    "    # 更新datamap\n",
    "    datamaps['attribute2id'] = attribute2id\n",
    "    datamaps['id2attribute'] = id2attribute\n",
    "    datamaps['attributeid2num'] = attributeid2num\n",
    "    return len(attribute2id), np.mean(attribute_lens), datamaps, items2attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_process import parse_meta\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Amazon_meta(dataset_name, data_maps):\n",
    "    datas = {}\n",
    "    meta_flie = './raw/meta_' + str(dataset_name) + '.json.gz'\n",
    "    item_asins = list(data_maps['str2id'].keys())\n",
    "    for info in tqdm(parse_meta(meta_flie)):\n",
    "        if info['asin'] not in item_asins:\n",
    "            continue\n",
    "        datas[info['asin']] = info\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_A = Amazon_meta(domain_A, item_dict[\"0\"])\n",
    "# meta_data_B = Amazon_meta(domain_B, item_dict[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(meta_data_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps(meta_data_A)\n",
    "with open(\"./handled/item2attributes_A.json\", 'w') as out:\n",
    "    out.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_B = Amazon_meta(domain_B, item_dict[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps(meta_data_B)\n",
    "with open(\"./handled/item2attributes_B.json\", 'w') as out:\n",
    "    out.write(json_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
